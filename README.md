# 数据介绍
&emsp;&emsp;使用深度学习算法做闲聊系统已经有一段时间了，回过头发现，大部分时间都在寻找优质训练。虽然网上有别人分享的闲聊数据，比如使用现有机器人（小黄鸡、小冰等）对话获得的数据（个人非常怀疑 数据的可用性，因为这些机器人本身的回答方式是基于匹配的，如果其匹配出错，训练自己的模型时，直接影响到模型的准确性，再加上，自己的模型并不能保证十分优秀，在优化模型的时候又需要担忧数据本身的问题）。另外就是字幕数据，网上有人出售3kw+行的字幕数据，仔细研究后发现噪音特别多，同时还有大量的重复，当然最主要的是上下两句无法判定是否是对话。在对话方面的paper，领域的大牛一般是以Ubuntu的问答数据来做，但只限于Ubuntu这个特定的领域，无法满足我们想开发闲聊机器人的需求。

&emsp;&emsp;网上有报道，小冰刚出来的时候拥有2kw+问答对，同时每天有一定百分比的增长，而且声明其预料来自网络公共数据。应对开发闲聊系统的需求，经过一两个月的摸索，总算找到合适的闲聊数据，例子[链接](https://www.jianshu.com/p/2934d43a2e50)。

&emsp;&emsp;考虑到数据收集的艰辛（另外，为了训练[w2v](https://www.jianshu.com/p/ae5b45e96dbf)，爬取了某百科800w+数据、300g+小说、[400w+新闻](https://www.jianshu.com/p/370d3e67a18f)等），想把收集的数据售出（恕不告知数据来源），让更多的人来解决“深度学习做对话系统”这个难题，说是他是难题，因为太多东西要去解决。目前深度学习做对话系统，主流的核心算法是seq2seq，之后还有很多优化算法，如使用beam search解决前k个字符概率乘积最大、考虑低频回复的MMI，兼顾问题前后字符的信息——attention mechanism，解决连续多轮的问答HRED，同时使用reinforcement learning也能在一定程度上解决多轮问题。总的来说，这些优秀的算法在一定程度上确实解决了问题，不过你还是得有合适的数据（如多轮问答数据）才能测试、评估、改进等。所以想通过售卖数据方式，希望大家一起解决这个难题——毕竟智能对话是多么吸引人，而且未来一定是各大公司必争之地。如果对这方面的研究有浓厚的兴趣，欢迎大家通过邮件（3492562997@qq.com）交流。

样例可见：[对话语料](https://www.jianshu.com/p/2934d43a2e50)

目前已有的数据统计（每天仍有增长-PS:由于平台封杀,已停止收集）：
单轮：600w
多轮：200w

**数据特点**
1. 可能有表情——eg：\(^o^)/YES!
2. 对话数据为短文本，字数平均长度在10以内
3. 极少数的对话是其它语言，eg：英语、日语、韩语等
4. 数据已去重

**定价**
1. 单轮定价：100w组/510元
2. 多轮每百万组定价（平均轮数为4.40±）：2000

**备注**
1. 100w起售 
2. 购买时如果有能力证明自己是学生的，购买一律9折，证明方式：学生证或一卡通及身份证主页照片，承诺不保存照片
3. 对于数据仍有疑问的，可留言，在下感激不尽
4. 如果大家想切实看到对话效果，可考虑买多轮数据
5. 有意购买，可联系客服qq：3492562997。恕不讨价
